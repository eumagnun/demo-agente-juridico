# Software criado apenas para fins de testes, sem qualquer tipo de garantia
## Agente Jur√≠dico com Vertex AI e Databricks

Este projeto demonstra a cria√ß√£o de um assistente de IA (agente) de ponta a ponta, capaz de consultar uma base de dados de processos jur√≠dicos hospedada no Databricks. O agente utiliza o Agent Development Kit (ADK) do Google e √© implantado no Vertex AI Agent Engine, tornando-se acess√≠vel atrav√©s do Agentspace.

## Vis√£o Geral da Arquitetura

A solu√ß√£o √© composta pelos seguintes componentes:

  * **Fonte de Dados (Databricks):** Uma tabela Delta no Databricks armazena os dados dos processos jur√≠dicos. Para este exemplo, os dados s√£o gerados de forma fict√≠cia.
  * **Agente de IA (Google ADK):** O "c√©rebro" da opera√ß√£o, constru√≠do em Python com o ADK. Ele √© composto por:
      * `root_agent`: O agente principal que interage com o usu√°rio.
      * `advogado_agent`: Um sub-agente especialista com a persona de um advogado para an√°lises mais detalhadas.
      * `get_info_processos_juridicos`: Uma ferramenta (tool) que se conecta √† API do Databricks para executar consultas SQL de forma segura.
  * **Hospedagem (Vertex AI Agent Engine):** O agente √© empacotado e implantado como um servi√ßo escal√°vel e gerenci√°vel no Google Cloud.
  * **Interface de Uso (Agentspace):** O agente implantado √© registrado no Agentspace, tornando-se detect√°vel e pronto para uso.

## Pr√©-requisitos

Antes de come√ßar, garanta que voc√™ tenha:

**Google Cloud:**

  * Um projeto no Google Cloud com a API do Vertex AI ativada.
  * `gcloud` CLI instalado e autenticado (`gcloud auth login`).
  * Um bucket no Cloud Storage para staging.

**Databricks:**

  * Um workspace no Databricks.
  * Um SQL Warehouse em execu√ß√£o e seu respectivo ID.
  * Um Service Principal (Principal de Servi√ßo) com permiss√£o para acessar o SQL Warehouse.
  * As credenciais do Service Principal (Client ID e Client Secret).

**Python:**

  * Python 3.9 ou superior.
  * `pip` para gerenciamento de pacotes.

-----

## üöÄ Guia de Instala√ß√£o e Deploy

Siga estes passos para configurar e implantar o agente.

### 1\. Prepara√ß√£o do Ambiente Local

Clone o reposit√≥rio e configure o ambiente Python.

```bash
# Clone o reposit√≥rio
git clone https://github.com/eumagnun/demo-agente-juridico
cd demo-agente-juridico

# Crie e ative um ambiente virtual
python -m venv .venv
source .venv/bin/activate

# Instale as depend√™ncias
pip install -r requirements.txt
```

### 2\. Configura√ß√£o das Vari√°veis de Ambiente

As credenciais e configura√ß√µes s√£o gerenciadas atrav√©s de vari√°veis de ambiente.

Copie o arquivo de exemplo:

```bash
cp main_agent/.env-example main_agent/.env
```

Edite o arquivo `main_agent/.env` e preencha com suas credenciais do Google Cloud e Databricks:

```ini
GOOGLE_GENAI_USE_VERTEXAI=TRUE
GOOGLE_CLOUD_PROJECT=[SEU_PROJECT_ID]
GOOGLE_CLOUD_LOCATION=us-central1

DATABRICKS_WORKSPACE_URL=[SUA_DATABRICKS_WORKSPACE_URL]
DATABRICKS_CLIENT_ID=[SEU_DATABRICKS_CLIENT_ID]
DATABRICKS_CLIENT_SECRET=[SEU_DATABRICKS_CLIENT_SECRET]
DATABRICKS_WAREHOUSE_ID=[SEU_DATABRICKS_WAREHOUSE_ID]
```

### 3\. Gera√ß√£o dos Dados no Databricks

Antes de o agente poder consultar os dados, voc√™ precisa cri√°-los no Databricks. Utilize o script de gera√ß√£o de dados fornecido e execute-o em um notebook no seu workspace Databricks. Ele criar√° a tabela `processos_juridicos` necess√°ria para o agente.
```Python
# Importando as bibliotecas necess√°rias para a sess√£o Spark, tipos de dados e gera√ß√£o de dados

from pyspark.sql import SparkSession
from pyspark.sql.types import StructType, StructField, StringType, IntegerType, DateType, DoubleType
from faker import Faker
import random
from datetime import datetime, timedelta

# Inicializa o Faker para gerar dados em portugu√™s do Brasil
fake = Faker('pt_BR')

# --- Par√¢metros de Gera√ß√£o ---
num_processos = 1000 # Altere este n√∫mero para gerar mais ou menos dados

# --- Listas de Dados para Simula√ß√£o (garante consist√™ncia e realismo) ---
varas = ["1¬™ Vara C√≠vel", "2¬™ Vara de Fam√≠lia", "Vara do Juizado Especial C√≠vel", "1¬™ Vara Criminal", "2¬™ Vara da Fazenda P√∫blica"]
comarcas = ["S√£o Paulo", "Rio de Janeiro", "Belo Horizonte", "Porto Alegre", "Salvador"]
status_processo = ["Em andamento", "Arquivado", "Julgado", "Suspenso", "Em recurso"]
tipos_acao = ["A√ß√£o de Cobran√ßa", "Div√≥rcio Litigioso", "Reclama√ß√£o Trabalhista", "Busca e Apreens√£o", "Invent√°rio"]

# --- Fun√ß√£o para gerar um processo aleat√≥rio ---
def gerar_processo(processo_id):
    data_abertura = fake.date_time_between(start_date='-5y', end_date='now').date()
    # Garante que a √∫ltima movimenta√ß√£o seja sempre ap√≥s a data de abertura
    data_movimentacao = fake.date_time_between(start_date=data_abertura, end_date='now').date()
    # Cria um n√∫mero de processo em um formato comum no Brasil (simplificado)
    numero_processo = f"{random.randint(1000000, 9999999)}-{random.randint(10, 99)}.{datetime.now().year}.{random.randint(1, 9)}.{random.randint(10, 99)}.{random.randint(1000, 9999)}"

    return {
        "id_processo": processo_id,
        "numero_processo": numero_processo,
        "vara": random.choice(varas),
        "comarca": random.choice(comarcas),
        "status": random.choice(status_processo),
        "data_abertura": data_abertura,
        "data_ultima_movimentacao": data_movimentacao,
        "tipo_acao": random.choice(tipos_acao),
        "parte_autora": fake.name(),
        "advogado_autor": f"{fake.name()} (OAB/{fake.state_abbr()}{random.randint(10000, 99999)})",
        "parte_re": fake.company(),
        "advogado_reu": f"{fake.name()} (OAB/{fake.state_abbr()}{random.randint(10000, 99999)})",
        "valor_causa": round(random.uniform(1000.0, 500000.0), 2)
    }

# Gerando a lista de dados usando a fun√ß√£o acima
dados_processos = [gerar_processo(i) for i in range(1, num_processos + 1)]

# Definindo o schema (a "planta" da nossa tabela)
# Por que definir um schema? Isso garante que os dados sejam carregados com os tipos corretos (data, texto, n√∫mero), evitando erros de interpreta√ß√£o.
schema = StructType([
    StructField("id_processo", IntegerType(), False),
    StructField("numero_processo", StringType(), True),
    StructField("vara", StringType(), True),
    StructField("comarca", StringType(), True),
    StructField("status", StringType(), True),
    StructField("data_abertura", DateType(), True),
    StructField("data_ultima_movimentacao", DateType(), True),
    StructField("tipo_acao", StringType(), True),
    StructField("parte_autora", StringType(), True),
    StructField("advogado_autor", StringType(), True),
    StructField("parte_re", StringType(), True),
    StructField("advogado_reu", StringType(), True),
    StructField("valor_causa", DoubleType(), True)
])

# Criando o DataFrame do Spark a partir dos dados e do schema
df_processos = spark.createDataFrame(dados_processos, schema)

# --- Salvando os dados como uma tabela Delta ---
nome_tabela = "processos_juridicos"
# O modo "overwrite" substituir√° a tabela se ela j√° existir, √∫til para testes.
df_processos.write.format("delta").mode("overwrite").saveAsTable(nome_tabela)

print(f"Tabela '{nome_tabela}' criada com sucesso com {num_processos} registros.")
display(df_processos) # Exibe uma amostra interativa dos dados
```

### 4\. Deploy do Agente no Vertex AI

O script **`agent_engine_deploy.py`** empacota e implanta seu agente no Vertex AI Reasoning Engines.

Edite o arquivo `agent_engine_deploy.py` e substitua os placeholders:

```python
vertexai.init(project="[SEU_PROJECT_ID]", staging_bucket="gs://[SEU_BUCKET_PARA_STAGING]")
```

Execute o script de deploy:

```bash
python agent_engine_deploy.py
```

Ao final da execu√ß√£o, o terminal exibir√° os detalhes do agente implantado. Copie o **`resource_name`** completo do agente, pois voc√™ precisar√° dele no pr√≥ximo passo. Ele ter√° o formato: `projects/SEU_PROJECT_NUMBER/locations/us-central1/reasoningEngines/ID_DO_AGENTE`.

### 5\. Registro no Agentspace

O √∫ltimo passo √© tornar seu agente vis√≠vel no Agentspace.

Edite o script **`register_to_agentspace.sh`** e preencha as vari√°veis com seus dados:

```bash
export PROJECT_ID=[SEU_PROJECT_ID]
export PROJECT_NUMBER=[SEU_PROJECT_NUMBER]
export REASONING_ENGINE_RES=[COLE_O_RESOURCE_NAME_DO_PASSO_ANTERIOR_AQUI]
export AS_APP="[ID_DA_SUA_APLICACAO_NO_AGENTSPACE]"
```

Execute o script:

```bash
bash register_to_agentspace.sh
```

Pronto\! Seu agente jur√≠dico agora est√° implantado e dispon√≠vel no seu Agentspace para responder a perguntas como: *"Quantos processos est√£o com o status 'Em andamento'?"*.

-----

## Estrutura do Projeto

```
.
‚îú‚îÄ‚îÄ agent_engine_deploy.py      # Script para deploy no Vertex AI Reasoning Engines.
‚îú‚îÄ‚îÄ main_agent/
‚îÇ   ‚îú‚îÄ‚îÄ .env                    # (Local) Credenciais e configura√ß√µes.
‚îÇ   ‚îú‚îÄ‚îÄ .env-example            # Template para o arquivo .env.
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py             # Inicializador do m√≥dulo.
‚îÇ   ‚îî‚îÄ‚îÄ agent.py                # L√≥gica principal do agente, ferramentas e sub-agentes.
‚îú‚îÄ‚îÄ register_to_agentspace.sh   # Script para registrar o agente no Agentspace.
‚îú‚îÄ‚îÄ requirements.txt            # Depend√™ncias Python do projeto.
‚îî‚îÄ‚îÄ .gitignore                  # Arquivos e pastas a serem ignorados pelo Git.
```
